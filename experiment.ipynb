{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os.path\n","\n","import pandas as pd\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.model_selection import train_test_split\n","from transformers import (BertTokenizerFast, Trainer, TrainingArguments)\n","\n","from utils import *\n","\n","RANDOM_STATE = 49\n","\n","# 0 = don't use summary, 1 = abstractive, 2 = extractive\n","IS_USE_SUMMARY_TRAIN = 0\n","IS_USE_SUMMARY_TEST = 0\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_file = \"training.csv\"\n","testing_file = \"testing.csv\"\n","if not os.path.isfile(training_file):\n","    df = pd.read_csv(\"task_3a_sample_data.csv\", sep=\"\\t\", header=0)\n","    df_2 = pd.read_csv(\"Task3a_training.csv\", header=0)\n","    df = df.append(df_2)\n","    generate_extractive_summaries(df, training_file)\n","    df = pd.read_csv(training_file)\n","    generate_abstractive_summaries(df, training_file)\n","\n","if not os.path.isfile(testing_file):\n","    df = pd.read_csv(\"Task3a_testing.csv\", header=0)\n","    generate_extractive_summaries(df, testing_file)\n","    df = pd.read_csv(testing_file)\n","    generate_abstractive_summaries(df, testing_file)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"training.csv\")\n","df['label'] = df['our rating'].apply(convert_to_int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_train, df_val = train_test_split(\n","    df, test_size=0.2, stratify=df['our rating'], random_state=RANDOM_STATE)\n","\n","df_test = pd.read_csv(\"testing.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ros = RandomOverSampler()\n","x_resampled, y_resampled = ros.fit_resample(\n","    df_train.iloc[:, 0:-1], df_train[\"label\"])\n","data_oversampled = pd.concat(\n","    [pd.DataFrame(x_resampled), pd.DataFrame(y_resampled)], axis=1)\n","df_train = data_oversampled\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","train_encodings, train_labels = get_encodings(\n","    df_train, tokenizer, IS_USE_SUMMARY_TRAIN)\n","val_encodings, val_labels = get_encodings(\n","    df_val, tokenizer, IS_USE_SUMMARY_TEST)\n","\n","test_encodings = get_encodings_test(\n","    df_test, tokenizer, IS_USE_SUMMARY_TEST)\n","\n","train_dataset = CheckThatLabDataset(train_encodings, train_labels)\n","val_dataset = CheckThatLabDataset(val_encodings, val_labels)\n","test_dataset = CheckThatLabDatasetTest(test_encodings)\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=8,   # batch size per device during training\n","    per_device_eval_batch_size=8,    # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=50,\n","    load_best_model_at_end=True,\n","    seed=RANDOM_STATE,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = Trainer(\n","    # the instantiated ðŸ¤— Transformers model to be trained\n","    model_init=init_full_text_model,\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset,            # evaluation dataset\n","    data_collator=None,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluation_results = trainer.evaluate()\n","print(evaluation_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred = trainer.predict(test_dataset)\n","preds = pred.predictions.argmax(-1)\n","df_test['label'] = preds\n","df_test['our rating'] = df_test['label'].apply(convert_to_rating)\n","columns = [\"public_id\", \"our rating\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if(IS_USE_SUMMARY_TRAIN == 0):\n","    df_test.to_csv(\"predictions.csv\", columns=columns, index=False)\n","elif(IS_USE_SUMMARY_TRAIN == 1):\n","    df_test.to_csv(\"predictions_abstractive.csv\", columns=columns, index=False)\n","else:\n","    df_test.to_csv(\"predictions_extractive.csv\", columns=columns, index=False)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}